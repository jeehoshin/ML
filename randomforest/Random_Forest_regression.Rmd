---
title: "random_forest_regression"
output: github_document
---

# [0] 데이터 준비

```{r}
library(knitr)
library(rmarkdown)
library(dplyr)
library(data.table)

data <- fread('day.csv')
str(data)
sapply(data, class)
data <- data %>% select(-instant, -dteday)
data <- transform(
  data,
  season = as.factor(season),
  yr = as.factor(yr), 
  mnth = as.factor(mnth), 
  holiday = as.factor(holiday),
  weekday = as.factor(weekday),
  workingday = as.factor(workingday), 
  weathersit = as.factor(weathersit), 
  temp = as.numeric(temp), 
  atemp = as.numeric(atemp),
  hum = as.numeric(hum),
  windspeed = as.numeric(windspeed), 
  casual = as.numeric(casual), 
  registered = as.numeric(registered), 
  cnt = as.numeric(cnt)
)
sapply(data, class)
head(data)
```

# [1] 가장 기본적이면서도 복잡하고 정교한 방법

## [1 - 1] 데이터 준비

```{r}
library(caret)
set.seed(1234)
index <- createDataPartition(data$cnt, p = .7, list = F) #이건 데이터를 나눠주는 함수.. 개꿀딱지임
data.train <- data[index,]
data.holdout <- data[-index,]
```

## [1 - 2] 기본 parameter로 적합시키기.


```{r}
library(randomForest)
trControl <- trainControl(method = "cv",number = 10,  search = "grid") 
#cv방법으로 10fold. 즉 10-fold cv를 한다는 의미이다.
rf_default <- train(cnt~., data = data.train,
    method = "rf",
    metric = "RMSE",
    trControl = trControl)

#결과를 추출하자
print(rf_default)
```

> #### 물론 이때 trainControl을 다르게 해줄 수 있다. 예를 들면 

```{r eval = F}
trControl <- trainControl(method = "repeatedcv",number = 10,  repeats = 3, search = "grid") 
```

> 이렇게 해주면 repeatedcv를 해준다는 뜻이다(3번) 근데 사용해보니 오히려 위 방법이 holdout에 대한 정확도를 떨어뜨렸다. 아마 과적합되게 만들지 않았을까 생각이 들긴 하는데... 사실 위 방법을 쓰니 maxnodes 값이 달라졌다.

> #### 당연히 search = 'random'으로 해주면 랜덤 서치를 해준다. mtry값은 데이터의 변수의 개수가 그 최대값이라서 오히려 그리드 서치 방법이 합리적일 수 있다. 

### mtry = 2에서 가장 결과가 좋음을 알 수 있다. 여기서 더 발전시켜서 찾아보자.


### [1 - 3] mtry 찾기 

```{r}
set.seed(1234)
tuneGrid <- expand.grid(.mtry = c(1: 13)) #기본에서 찾은 가장 좋은 mtry를 기준으로 넣어주면 된다. 
rf_mtry <- train(cnt~., data = data.train,
    method = "rf", metric = "RMSE",
    tuneGrid = tuneGrid, #이렇게 그리드 서치를 진행해준다. 
    trControl = trControl,  importance = TRUE, nodesize = 14, ntree = 300)
print(rf_mtry)
plot(rf_mtry)
```

> plot 으로 보면 조금 더 편할 수 있다. 근데 만약 최적의 mtry가 마지막 부분에서 급상승하는 그래프를 그린다면, 그보다 더 큰 mtry를 포함하는 parameter tuning을 다시 진행해줘야 할 것이다. 

> 아마 여기의 결과는 5번의 cv의 평균 에러(여기서는 accuracy)일 것이다. 그니께 1:10까지의 파라미터의 결과가 총 다섯번이 나오는데 print(rf_mtry)의 값은 이 다섯번의 결과를 평균낸 cv_error일 것으로 예상된다. 사실 그래야 말이 되긴 함.

```{r}
opt.mtry <- rf_mtry$bestTune$mtry
max(rf_mtry$results$Accuracy) #이거는 가장 높은 정확도!
opt.mtry #가장 좋은 mtry는 1이다.. 즉 변수 하나만 쓰라는 이야기
```

> #### 위와 같은 방식으로 mtry를 찾아주면 된다. 시간이 없다면 밑의 과정들은 생략해도 될듯? 실제로 랜포의 장점은 mtry만 찾고도 꽤나 좋은 성능을 내는 것이라고 하니


## [1 - 4] maxnodes 찾기

```{r}
store_maxnode <- list()
tuneGrid <- expand.grid(.mtry = opt.mtry) #위에서 찾은 최고의 mtry를 넣어준다. 
for (maxnodes in c(5: 30)) {
    set.seed(1234)
    rf_maxnode <- train(cnt~.,
        data = data.train, method = "rf", metric = "RMSE",
        tuneGrid = tuneGrid, #여기는 아까 찾은 베스트 mtry가 들어있다.
        trControl = trControl,importance = TRUE,nodesize = 14,
        maxnodes = maxnodes, #이제 이 값을 5부터 30까지 바꿔줄 것이다. 
        ntree = 300)
    current_iteration <- toString(maxnodes)
    store_maxnode[[current_iteration]] <- rf_maxnode
}

results_mtry <- resamples(store_maxnode)
result.maxnode<- summary(results_mtry)$statistics$RMSE %>% as.data.frame()
opt.maxnodes <- as.numeric(row.names(result.maxnode[which.min(result.maxnode$Mean),])) # 뭐 대충 이런 방식으로 넣어주면 된다. 
#근데 여기서 최소값을 봐야할지 평균값을 봐야할지는 모르겠다. 이전의 classification은 최대값을 봤으니 여기서는 평균값을 봐보자. 
```

> 여기서는 RMSE이기 때문에 최저값을 찾아줘야하는게 포인트! classification과는 다르다. 


## [1 - 5] ntree 찾기

```{r}
store_maxtrees <- list()
for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {
    set.seed(1234)
    rf_maxtrees <- train(cnt~.,
        data = data.train,
        method = "rf",
        metric = "RMSE",
        tuneGrid = tuneGrid,
        trControl = trControl,
        importance = TRUE,
        nodesize = 14,
        maxnodes = opt.maxnodes,
        ntree = ntree)
    key <- toString(ntree)
    store_maxtrees[[key]] <- rf_maxtrees
}
results_tree <- resamples(store_maxtrees)
summary(results_tree)
result.ntree<- summary(results_tree)$statistics$RMSE %>% as.data.frame()
opt.ntree <- as.numeric(row.names(result.ntree[which.min(result.ntree$Mean),]))
```


> 결과적으로 opt.mtry, opt.ntree, opt.maxnodes를 얻게 되었다. 이 세가지의 파라미터를 가지고 최종 모델을 적합한다. 

## [1 - 6] 최종모델 적합.

```{r}
set.seed(1234)
fit_rf <- randomForest(cnt~.,
    data = data.train,
    metric = "RMSE",
    mtry = opt.mtry, #우리가 찾은 베스트 mtry
    importance = TRUE,
    nodesize = 14,
    ntree = opt.ntree, #우리가 찾은 베스트 ntree
   maxnodes = opt.maxnodes) #우리가 찾은 베스트 maxnodes
```

## [1 - 7] 모델 평가

```{r}
rf.prediction <-predict(fit_rf, data.holdout)
RMSE(rf.prediction, data.holdout$cnt) #최종 RMSE : 190.769
varImpPlot(fit_rf)
```

> #### 우선 summary(data$cnt) 하면 평균값이 4504인 것을 보면 꽤나 괜찮게 나온 것임을 알 수 있다!

# [2] CV 과정에서 data셋을 customize해주는 방법. 

> #### 사실 이 방법은 **시계열 데이터**에 대해 모델링을 진행할 때 써야한다. 단순히 cv로 하게 되면 미래의 데이터로 학습하고 과거의 데이터를 예측하는 이상한 모델이 될 수 있기 때문이다! 그래서 롤링 윈도우를쓰긴 하는데 ML에서는 아무래도 train set을 적당히 나눠주는 것 같다. 

## [2 - 1] 일단 caret 패키지로 cv를 만드는 방법을 알아보자. 

```{r}
#train data 만들어주기
set.seed(1234) #set.seed 해주는 습관 = good
folds <- createFolds(data.train$cnt, k = 5, returnTrain = T)
```

> #### 놀랍게도 이렇게 cv를 위한 셋을 만들 수 있다. 여기서 원래 데이터를 쓰면 안된다. data.holdout은 무조건 나중에 딱 한번만 건드리는 것이다.

```{r}
#test 셋 만들기
fold_test <- list()
for (i in 1:5) { 
fold_test[[paste0('fold', i)]] <- setdiff(1:nrow(data.train), folds[[i]])
  }
```

## [2 - 2] index를 어떻게 적용하는가?

```{r}
trControl <- trainControl(method = "cv",number = 10,
                          index = folds, #이렇게 index라는 argument로 넣어주면 된당!
                          savePredictions = 'final' , search = "grid") 
tuneGrid <- expand.grid(.mtry = (1:ncol(data.train)))
#cv방법으로 10fold. 즉 10-fold cv를 한다는 의미이다.
rf_default <- train(cnt~., data = data.train,
    method = "rf",
    metric = "RMSE",
    trControl = trControl,
    tuneGrid = tuneGrid)
rf_default$results
```

## [2 - 3] 이 커스텀 한 방법은 OOF를 적용할 수 있다고 한다...? 근데 이건 뭐하는 건지 잘 모르겠다.

```{r}
rf_oof_pred <- rf_default$pred
rf_oof_pred$Resample <- as.factor(rf_oof_pred$Resample)
rf_oof_pred <- rf_oof_pred[order(rf_oof_pred$rowIndex),]
str(rf_oof_pred)
```